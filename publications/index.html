<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!-- Metadata, OpenGraph and Schema.org -->


    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Publications | Can Cui</title>
    <meta name="author" content="Can  Cui">
    <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


<!-- Bootstrap & MDB -->
<link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

<!-- Bootstrap Table -->
<link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.css">

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons/css/academicons.min.css">
<!--      href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css"-->
<!--      integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">-->
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">



<!-- Styles -->

<link rel="shortcut icon" href="/assets/img/karby.png">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="https://cancui19.github.io//publications/">

<!-- Dark Mode -->

<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>


  </head>

  <!-- Body -->
  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header --><header>

  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      <a class="navbar-brand title font-weight-lighter" href="/">Can Cui</a>
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">

          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">About me</a>
          </li>
          

          <!-- Other pages -->
          <li class="nav-item active">
            <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a>
          </li>
          <li class="nav-item dropdown ">
            <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Intersts</a>
            <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
              <a class="dropdown-item" href="/cats/">Cats</a>
              <a class="dropdown-item" href="/soccers/">Soccers</a>
              <a class="dropdown-item" href="/music/">Music</a>
            </div>
          </li>

          <!-- Toogle theme mode -->
          <li class="toggle-container">
            <button id="light-toggle" title="Change theme">
              <i class="fas fa-moon"></i>
              <i class="fas fa-sun"></i>
            </button>
          </li>
        </ul>
      </div>
    </div>
  </nav>
  
</header>

    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Publications</h1>
            <p class="post-description"></p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">
<h2 class="year">2023</h2>
<ol class="bibliography">
<li>
<!--stole from: https://github.com/boleizhou/boleizhou.github.io/blob/master/_layouts/bib.html-->
<div class="row">
    <div class="col-sm-3 abbr">
        
        <img src="../assets/teaser/cover_receive.png" class="teaser img-fluid z-depth-1">
        
        
        
        <abbr class="badge">under review</abbr>
        
        
    </div>

    <div id="cui_receive_2023" class="col-sm-9">
        
        <!-- Title -->
        <div class="title">Receive, Reason, and React: Drive as You Say with Large Language Models in Autonomous Vehicles</div>
        <!-- Author -->
        <div class="author">
            <em><b>Can Cui</b></em>, <a href="https://maysonma.github.io/" rel="external nofollow noopener" target="_blank">Yunsheng Ma</a>, <a href="https://www.irohxucao.com/" rel="external nofollow noopener" target="_blank">Xu Cao</a>, <a href="https://wenqian-ye.github.io/" rel="external nofollow noopener" target="_blank">Wenqian Ye</a>, and <a href="https://ziranw.github.io/" rel="external nofollow noopener" target="_blank">Ziran Wang</a>
            
        </div>
        <div class="periodical">
            
            <em>In reviewing</em>
            
            
            (<b>under review</b>)
            
            
            , 2023
            
            </div>
        

        <!-- Links/Buttons -->
        <div class="links">
            
            
            
            <a href="http://arxiv.org/abs/2310.08034" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a>
            
            
            
            
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        

        <!-- Hidden bibtex block -->
        
    </div>
</div>
</li>
<li>
<!--stole from: https://github.com/boleizhou/boleizhou.github.io/blob/master/_layouts/bib.html-->
<div class="row">
    <div class="col-sm-3 abbr">
        
        <img src="../assets/teaser/cover_drive.png" class="teaser img-fluid z-depth-1">
        
        
        
        <abbr class="badge">under review</abbr>
        
        
    </div>

    <div id="cui_drive_2023" class="col-sm-9">
        
        <!-- Title -->
        <div class="title">Drive as You Speak: Enabling Human-Like Interaction with Large Language Models in Autonomous Vehicles</div>
        <!-- Author -->
        <div class="author">
            <em><b>Can Cui</b></em>, <a href="https://maysonma.github.io/" rel="external nofollow noopener" target="_blank">Yunsheng Ma</a>, <a href="https://www.irohxucao.com/" rel="external nofollow noopener" target="_blank">Xu Cao</a>, <a href="https://wenqian-ye.github.io/" rel="external nofollow noopener" target="_blank">Wenqian Ye</a>, and <a href="https://ziranw.github.io/" rel="external nofollow noopener" target="_blank">Ziran Wang</a>
            
        </div>
        <div class="periodical">
            
            <em>In reviewing</em>
            
            
            (<b>under review</b>)
            
            
            , 2023
            
            </div>
        

        <!-- Links/Buttons -->
        <div class="links">
            
            
            
            <a href="http://arxiv.org/abs/2309.10228" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a>
            
            
            
            
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        

        <!-- Hidden bibtex block -->
        
    </div>
</div>
</li>
<li>
<!--stole from: https://github.com/boleizhou/boleizhou.github.io/blob/master/_layouts/bib.html-->
<div class="row">
    <div class="col-sm-3 abbr">
        
        <img src="../assets/teaser/cover_red.png" class="teaser img-fluid z-depth-1">
        
        
        
        <abbr class="badge">T-IV</abbr>
        
        
    </div>

    <div id="cui_red_2023" class="col-sm-9">
        
        <!-- Title -->
        <div class="title">REDFormer: Radar Enlightens the Darkness of Camera Perception with Transformers</div>
        <!-- Author -->
        <div class="author">
            <em><b>Can Cui</b></em>, <a href="https://maysonma.github.io/" rel="external nofollow noopener" target="_blank">Yunsheng Ma</a>, <a href="https://www.linkedin.com/in/juanwu-lu/" rel="external nofollow noopener" target="_blank">Juanwu Lu</a>, and <a href="https://ziranw.github.io/" rel="external nofollow noopener" target="_blank">Ziran Wang</a>
            
        </div>
        <div class="periodical">
            
            <em>In Proceedings of the IEEE Transactions on Intelligent Vehicles</em>
            
            
            (<b>T-IV</b>)
            
            
            , 2023
            
            </div>
        

        <!-- Links/Buttons -->
        <div class="links">
            
            
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            
            
            
            
            
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        
        <div class="abstract hidden">
            <p>Enhancing the accuracy and reliability of perception systems in automated vehicles is critical, especially under varying driving conditions. Unfortunately, the challenges of adverse weather and low-visibility conditions can seriously degrade camera performance, introducing significant risks to vehicle safety. To address these concerns, in this study, we introduce a novel transformer-based 3D object detection model named ‘REDFormer’. By exploiting bird’s-eye-view camera-radar fusion, the REDFormer offers a more practical and financially viable solution for tackling low-visibility conditions. We validate our model using the comprehensive nuScenes dataset, incorporating camera images, multi-radar point clouds, weather information, and time-of-day data. In comparative analyses, our model surpasses state-of-the-art benchmarks in both classification and detection accuracy. An in-depth ablation study further elucidates the individual contributions of each model component in overcoming the challenges posed by weather and lighting conditions. Experimental results specifically highlight the model’s significant performance improvements, demonstrating a 31.31% increase in accuracy under rainy conditions and a 46.99% enhancement during nighttime scenarios, affirming REDFormer’s potential as a robust and cost-effective solution for automated vehicles.</p>
        </div>
        

        <!-- Hidden bibtex block -->
        
    </div>
</div>
</li>
<li>
<!--stole from: https://github.com/boleizhou/boleizhou.github.io/blob/master/_layouts/bib.html-->
<div class="row">
    <div class="col-sm-3 abbr">
        
        <img src="../assets/teaser/cover_macp.png" class="teaser img-fluid z-depth-1">
        
        
        
        <abbr class="badge">WACV</abbr>
        
        
    </div>

    <div id="ma_macp_2024" class="col-sm-9">
        
        <!-- Title -->
        <div class="title">MACP: Efficient Model Adaptation for Cooperative Perception</div>
        <!-- Author -->
        <div class="author">
<a href="https://maysonma.github.io/" rel="external nofollow noopener" target="_blank">Yunsheng Ma</a>, <a href="https://www.linkedin.com/in/juanwu-lu/" rel="external nofollow noopener" target="_blank">Juanwu Lu</a>, 
            <em><b>Can Cui</b></em>, <a href="https://sites.google.com/view/schzhao" rel="external nofollow noopener" target="_blank">Sicheng Zhao</a>, <a href="https://www.irohxucao.com/" rel="external nofollow noopener" target="_blank">Xu Cao</a>, <a href="https://wenqian-ye.github.io/" rel="external nofollow noopener" target="_blank">Wenqian Ye</a>, and <a href="https://ziranw.github.io/" rel="external nofollow noopener" target="_blank">Ziran Wang</a>
            
        </div>
        <div class="periodical">
            
            <em>In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</em>
            
            
            (<b>WACV</b>)
            
            
            , 2023
            
            </div>
        

        <!-- Links/Buttons -->
        <div class="links">
            
            
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            
            
            
            
            
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        
        <div class="abstract hidden">
            <p>Vehicle-to-vehicle (V2V) communications have greatly enhanced the perception capabilities of connected and automated vehicles (CAVs) by enabling information sharing to “see through the occlusions", resulting in significant performance improvements. However, developing and training complex multi-agent perception models from scratch can be expensive and unnecessary when existing single-agent models show remarkable generalization capabilities. In this paper, we propose a new framework termed MACP, which equips a single-agent pre-trained model with cooperation capabilities. We approach this objective by identifying the key challenges of shifting from single-agent to cooperative settings, adapting the model by freezing most of its parameters and adding a few lightweight modules. We demonstrate in our experiments that the proposed framework can effectively utilize cooperative observations and outperform other state-of-the-art approaches in both simulated and real-world cooperative perception benchmarks while requiring substantially fewer tunable parameters with reduced communication costs.</p>
        </div>
        

        <!-- Hidden bibtex block -->
        
    </div>
</div>
</li>
<li>
<!--stole from: https://github.com/boleizhou/boleizhou.github.io/blob/master/_layouts/bib.html-->
<div class="row">
    <div class="col-sm-3 abbr">
        
        <img src="../assets/teaser/cover_human.png" class="teaser img-fluid z-depth-1">
        
        
        
        <abbr class="badge">SEC</abbr>
        
        
    </div>

    <div id="cui_human_2023" class="col-sm-9">
        
        <!-- Title -->
        <div class="title">Human-Autonomy Teaming on Autonomous Vehicles with Large Language Model-Enabled Human Digital Twins</div>
        <!-- Author -->
        <div class="author">
            <em><b>Can Cui</b></em>, <a href="https://maysonma.github.io/" rel="external nofollow noopener" target="_blank">Yunsheng Ma</a>, <a href="https://www.irohxucao.com/" rel="external nofollow noopener" target="_blank">Xu Cao</a>, <a href="https://wenqian-ye.github.io/" rel="external nofollow noopener" target="_blank">Wenqian Ye</a>, and <a href="https://ziranw.github.io/" rel="external nofollow noopener" target="_blank">Ziran Wang</a>
            
        </div>
        <div class="periodical">
            
            <em>In Proceedings of the ACM/IEEE Symposium on Edge Computing</em>
            
            
            (<b>SEC</b>)
            
            
            , 2023
            
            </div>
        

        <!-- Links/Buttons -->
        <div class="links">
            
            
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            
            
            
            
            
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        
        <div class="abstract hidden">
            <p>The development of autonomous vehicles is dramatically reshaping the transportation landscape, bringing new challenges and opportunities in human-machine interaction. As autonomous vehicles evolve, understanding and responding to human intent becomes significant, and therefore require new ways of human-autonomy teaming. A human digital twin (HDT) is a virtual representation of an individual driver, capturing their preferences, behaviors, and physiological states, enabling machines to better understand and predict human needs and responses. In this paper, we explore how large language models (LLMs), like GPT-4 and LLaMA, together with HDTs are changing the way humans team up with autonomous vehicles. These LLMs help make our conversations with vehicles more natural and intuitive. By pairing them in HDTs, we can get real-time feedback and smarter responses. This combination offers not just easier control but also safer driving experiences. We will break down how this works, why it matters, and what we might expect in the future.</p>
        </div>
        

        <!-- Hidden bibtex block -->
        
    </div>
</div>
</li>
<li>
<!--stole from: https://github.com/boleizhou/boleizhou.github.io/blob/master/_layouts/bib.html-->
<div class="row">
    <div class="col-sm-3 abbr">
        
        <img src="../assets/teaser/cover_redformer.png" class="teaser img-fluid z-depth-1">
        
        
        
        <abbr class="badge">ITSC</abbr>
        
        
    </div>

    <div id="cui_radar_2023" class="col-sm-9">
        
        <!-- Title -->
        <div class="title">Radar Enlighten the Dark: Enhancing Low-Visibility Perception for Automated Vehicles with Camera-Radar Fusion</div>
        <!-- Author -->
        <div class="author">
            <em><b>Can Cui</b></em>, <a href="https://maysonma.github.io/" rel="external nofollow noopener" target="_blank">Yunsheng Ma</a>, <a href="https://www.linkedin.com/in/juanwu-lu/" rel="external nofollow noopener" target="_blank">Juanwu Lu</a>, and <a href="https://ziranw.github.io/" rel="external nofollow noopener" target="_blank">Ziran Wang</a>
            
        </div>
        <div class="periodical">
            
            <em>IEEE International Conference on Intelligent Transportation Systems</em>
            
            
            (<b>ITSC</b>)
            
            
            , 2023
            
            </div>
        

        <!-- Links/Buttons -->
        <div class="links">
            
            
            
            <a href="http://arxiv.org/abs/2305.17318" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a>
            
            
            
            
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        

        <!-- Hidden bibtex block -->
        
    </div>
</div>
</li>
</ol>


</div>

          </article>

        </div>

      
    </div>

    <!-- Footer --><footer class="sticky-bottom mt-5">
    <div class="container">
        <!-- <a href="https://www.easycounter.com/">
            <img src="https://www.easycounter.com/counter.php?maysonma"
                 border="0" alt="HTML Hit Counters"></a> -->
        <a href="https://www.easycounter.com/" rel="external nofollow noopener" target="_blank">
            <img src="https://www.easycounter.com/counter.php?cancui" border="0" alt="Web Site Hit Counters"></a>
        <!-- <br><a href="https://www.easycounter.com/">Web Site Hit Counters</a> -->

        unique visitors since September 2023.
    </div>
    <div class="container">
        © Copyright 2023 Can  Cui.
        Last updated: October 28, 2023.
    </div>

</footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', '');
  </script>
    

  </body>
</html>
